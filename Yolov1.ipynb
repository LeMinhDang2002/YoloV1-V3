{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Number Plate Region\\env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from utils import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_data(object):\n",
    "    def __init__(self, input_shape = (448, 448, 3), class_names = []):\n",
    "        self.input_shape = input_shape\n",
    "        # Get the quotient of a division between 2 numbers\n",
    "        self.grid_shape = input_shape[0]//64, input_shape[1]\n",
    "        self.class_names = class_names\n",
    "        self.class_num = len(class_names)\n",
    "        self.file_names = None\n",
    "\n",
    "    def read_file_to_dataset (\n",
    "        self, img_path = None, label_path = None,\n",
    "        label_format = \"labelimg\",\n",
    "        rescale = 1/255,\n",
    "        preprocessing = None,\n",
    "        augmenter = None,\n",
    "        aug_times = 1,\n",
    "        shuffle = True,\n",
    "        seed = None,\n",
    "        encoding = \"utf-8\",\n",
    "        thread_num = 10):\n",
    "        img_data, label_data, path_list = tools.read_file(\n",
    "            img_path=img_path, \n",
    "            label_path=label_path,\n",
    "            label_format=label_format,\n",
    "            size=self.input_shape[:2], \n",
    "            grid_shape=self.grid_shape,\n",
    "            class_names=self.class_names,\n",
    "            rescale=rescale,\n",
    "            preprocessing=preprocessing,\n",
    "            augmenter=augmenter,\n",
    "            aug_times=aug_times,\n",
    "            shuffle=shuffle, seed=seed,\n",
    "            encoding=encoding,\n",
    "            thread_num=thread_num)\n",
    "        \n",
    "        self.file_names = path_list\n",
    "\n",
    "        return img_data, label_data\n",
    "    \n",
    "    def vis_img(self, img, label_data,\n",
    "                conf_threshold=0.5,\n",
    "                show_conf=True,\n",
    "                nms_mode=0,\n",
    "                nms_threshold=0.5,\n",
    "                nms_sigma=0.5,\n",
    "                **kwargs):\n",
    "\n",
    "        return tools.vis_img(\n",
    "                             img, \n",
    "                             label_data, \n",
    "                             class_names=self.class_names,\n",
    "                             conf_threshold=conf_threshold,\n",
    "                             show_conf=show_conf,\n",
    "                             nms_mode=nms_mode,  \n",
    "                             nms_threshold=nms_threshold,\n",
    "                             nms_sigma=nms_sigma,\n",
    "                             **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice! Repeat!: 000021.jpg 4 295\n"
     ]
    }
   ],
   "source": [
    "class_names = ['0', '1', '2',  '3', '4', \n",
    "          '5', '6', '7',  '8','9']\n",
    "num_classes = len(class_names)\n",
    "yolo_data = Yolo_data(class_names=class_names)\n",
    "\n",
    "img_path = \"../01_1K_MNIST/mnist_train\"\n",
    "label_path = \"../01_1K_MNIST/xml_train/\"\n",
    "\n",
    "train_img, train_label = yolo_data.read_file_to_dataset(img_path, label_path, \n",
    "                                                        label_format=\"labelimg\", \n",
    "                                                        thread_num=50, shuffle=False)\n",
    "\n",
    "img_path   = \"../01_1K_MNIST/mnist_val/\"\n",
    "label_path = \"../01_1K_MNIST/xml_val/\"\n",
    "\n",
    "test_img, test_label = yolo_data.read_file_to_dataset(img_path, label_path,\n",
    "                                                    label_format=\"labelimg\",\n",
    "                                                    thread_num=50,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     yolo_data.vis_img(\n",
    "#         train_img[i], train_label[i],\n",
    "#         show_conf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "# from tensorflow.python.keras import Model\n",
    "from keras.layers import Input, Dense, InputLayer, Dropout, Flatten, Reshape, Conv2D, GlobalAveragePooling2D\n",
    "from keras.layers import concatenate, LeakyReLU, BatchNormalization, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_epoch = 10\n",
    "epsilon = 1e-07\n",
    "\n",
    "# Leaky Convolutional\n",
    "# def Conv2D_BN_Leaky(input_tensor, *args):\n",
    "#     # output_tensor = Conv2D(*args, padding='same', kernel_constraint='he_normal')(input_tensor)\n",
    "#     output_tensor = Conv2D(*args, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "#     output_tensor = BatchNormalization()(output_tensor)\n",
    "#     output_tensor = LeakyReLU(alpha=0.1)(output_tensor)\n",
    "#     return output_tensor\n",
    "\n",
    "def Conv2D_BN_Leaky(input_tensor, *args):\n",
    "    output_tensor = Conv2D(*args, \n",
    "                           padding='same',\n",
    "                           kernel_initializer='he_normal')(input_tensor)\n",
    "    output_tensor = BatchNormalization()(output_tensor)\n",
    "    output_tensor = LeakyReLU(alpha=0.1)(output_tensor)\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backbone\n",
    "def Backbone_darknet(input_tensor):\n",
    "    conv1 = Conv2D_BN_Leaky(input_tensor, 64, 7, 2)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D_BN_Leaky(pool1, 192, 3)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D_BN_Leaky(pool2, 128, 1)\n",
    "    conv3 = Conv2D_BN_Leaky(conv3, 256, 3)\n",
    "    conv3 = Conv2D_BN_Leaky(conv3, 256, 1)\n",
    "    conv3 = Conv2D_BN_Leaky(conv3, 512, 3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = pool3\n",
    "    for _ in range(4):\n",
    "        conv4 = Conv2D_BN_Leaky(conv4, 256, 1)\n",
    "        conv4 = Conv2D_BN_Leaky(conv4, 512, 3)\n",
    "    conv4 = Conv2D_BN_Leaky(conv4, 1024, 3)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D_BN_Leaky(pool4, 512, 1)\n",
    "    conv5 = Conv2D_BN_Leaky(conv5, 1024, 3)\n",
    "    conv5 = Conv2D_BN_Leaky(conv5, 512, 1)\n",
    "    conv5 = Conv2D_BN_Leaky(conv5, 1024, 3)\n",
    "    conv5 = Conv2D_BN_Leaky(conv5, 1024, 3)\n",
    "    conv5 = Conv2D_BN_Leaky(conv5, 1024, 3, 2)\n",
    "    \n",
    "    conv6 = Conv2D_BN_Leaky(conv5, 1024, 3)\n",
    "    conv6 = Conv2D_BN_Leaky(conv6, 1024, 3)\n",
    "    \n",
    "    return conv6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOLO Neck\n",
    "def yolo_neck(input_shape=(448, 448, 3),\n",
    "              pretrained_darknet=None):\n",
    "    inputs = Input(input_shape)\n",
    "    darknet = Model(inputs, Backbone_darknet(inputs))\n",
    "    if pretrained_darknet is not None:\n",
    "        darknet.set_weights(pretrained_darknet.get_weights())\n",
    "    \n",
    "    return darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOLO Head\n",
    "# def yolo_head(model_body, bbox_num = 2, class_num = 10):\n",
    "#     inputs = model_body.input\n",
    "#     output = model_body.output\n",
    "\n",
    "#     output = Flatten()(output)\n",
    "#     output = Dense(4096, activation='sigmoid')(output)\n",
    "\n",
    "#     outputs   = Dense(7*7*(5*2+num_classes), activation='sigmoid')(output)\n",
    "#     outputs   = Reshape((7, 7, 5*2+num_classes), name = 'output', dtype='float32')(outputs)\n",
    "    \n",
    "#     model = Model(inputs, outputs)\n",
    "\n",
    "#     return model\n",
    "\n",
    "def yolo_head(model_body, bbox_num=2, class_num=10):\n",
    "    inputs = model_body.input\n",
    "    output = model_body.output\n",
    "\n",
    "    xywhc_output = Conv2D(5*bbox_num, 1,\n",
    "                          padding='same',\n",
    "                          activation='sigmoid',\n",
    "                          kernel_initializer='he_normal')(output)\n",
    "    p_output = Conv2D(class_num, 1,\n",
    "                      padding = 'same',\n",
    "                      activation='softmax',\n",
    "                      kernel_initializer='he_normal')(output)\n",
    "\n",
    "    outputs = concatenate([xywhc_output, p_output], axis=3)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IOU\n",
    "def cal_iou(xywh_true, xywh_pred, grid_shape):\n",
    "    grid_shape = np.array(grid_shape[::-1])\n",
    "    xy_true = xywh_true[..., 0:2]/grid_shape # N*S*S*1*2\n",
    "    wh_true = xywh_true[..., 2:4] # N*S*S*1*2\n",
    "\n",
    "    xy_pred = xywh_pred[..., 0:2]/grid_shape # N*S*S*B*2\n",
    "    wh_pred = xywh_pred[..., 2:4]\n",
    "    \n",
    "    half_xy_true = wh_true / 2. # N*S*S*1*2\n",
    "    mins_true    = xy_true - half_xy_true\n",
    "    maxes_true   = xy_true + half_xy_true\n",
    "\n",
    "    half_xy_pred = wh_pred / 2. # N*S*S*B*2\n",
    "    mins_pred    = xy_pred - half_xy_pred\n",
    "    maxes_pred   = xy_pred + half_xy_pred       \n",
    "    \n",
    "    intersect_mins  = tf.maximum(mins_pred,  mins_true) # N*S*S*B*2\n",
    "    intersect_maxes = tf.minimum(maxes_pred, maxes_true)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1] # N*S*S*B\n",
    "    \n",
    "    true_areas = wh_true[..., 0] * wh_true[..., 1] # N*S*S*1\n",
    "    pred_areas = wh_pred[..., 0] * wh_pred[..., 1] # N*S*S*B\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = (intersect_areas + epsilon)/(union_areas + epsilon)\n",
    "    \n",
    "    return iou_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Function\n",
    "def wrap_yolo_loss(grid_shape,\n",
    "                   bbox_num,\n",
    "                   class_num,\n",
    "                   binary_weight=1,\n",
    "                   loss_weight=[1, 1, 1, 1],\n",
    "                   ):\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        xywhc_true = tf.reshape(\n",
    "            y_true[..., :-class_num],\n",
    "            (-1, *grid_shape, 1, 5)) # N*S*S*1*5\n",
    "        xywhc_pred = tf.reshape(\n",
    "            y_pred[..., :-class_num],\n",
    "            (-1, *grid_shape, bbox_num, 5)) # N*S*S*B*5\n",
    "        \n",
    "        print(y_true.shape)\n",
    "        print(y_pred.shape)\n",
    "\n",
    "        print(y_true[..., -class_num])\n",
    "        print(y_pred[..., -class_num])\n",
    "\n",
    "        print(*grid_shape)\n",
    "\n",
    "        iou_scores = cal_iou(xywhc_true, xywhc_pred, grid_shape) # N*S*S*B\n",
    "        \n",
    "        response_mask = tf.one_hot(tf.argmax(iou_scores, axis=-1),\n",
    "                                   depth=bbox_num,\n",
    "                                   dtype=xywhc_true.dtype) # N*S*S*B\n",
    "        response_mask_exp = tf.expand_dims(response_mask, axis=-1) # N*S*S*B*1\n",
    "\n",
    "        has_obj_mask = xywhc_true[..., 4] # N*S*S*1\n",
    "        has_obj_mask_exp = tf.expand_dims(has_obj_mask, axis=-1) # N*S*S*1*1\n",
    "        \n",
    "        no_obj_mask = 1 - has_obj_mask*response_mask # N*S*S*B\n",
    "\n",
    "        xy_true = xywhc_true[..., 0:2] # N*S*S*1*2\n",
    "        xy_pred = xywhc_pred[..., 0:2] # N*S*S*B*2\n",
    "\n",
    "        wh_true = tf.maximum(xywhc_true[..., 2:4], epsilon) # N*S*S*1*2\n",
    "        wh_pred = tf.maximum(xywhc_pred[..., 2:4], epsilon) # N*S*S*B*2\n",
    "\n",
    "        c_pred = xywhc_pred[..., 4] # N*S*S*B\n",
    "        \n",
    "        xy_loss = tf.reduce_sum(\n",
    "            tf.reduce_mean(\n",
    "                has_obj_mask_exp # N*S*S*1*1\n",
    "                *response_mask_exp # N*S*S*B*1\n",
    "                *tf.square(xy_true - xy_pred), # N*S*S*B*2\n",
    "                axis=0))\n",
    "\n",
    "        wh_loss = tf.reduce_sum(\n",
    "            tf.reduce_mean(\n",
    "                has_obj_mask_exp # N*S*S*1*1\n",
    "                *response_mask_exp # N*S*S*B*1\n",
    "                *tf.square(tf.sqrt(wh_true) - tf.sqrt(wh_pred)), # N*S*S*B*2\n",
    "                axis=0))\n",
    "\n",
    "        has_obj_c_loss = tf.reduce_sum(\n",
    "            tf.reduce_mean(\n",
    "                has_obj_mask # N*S*S*1\n",
    "                *response_mask # N*S*S*B\n",
    "                *tf.square(iou_scores - c_pred), # N*S*S*B\n",
    "                axis=0))\n",
    "\n",
    "        no_obj_c_loss = tf.reduce_sum(\n",
    "            tf.reduce_mean(\n",
    "                no_obj_mask # N*S*S*1\n",
    "                *(tf.square(0 - c_pred)), # N*S*S*B\n",
    "                axis=0))\n",
    "        \n",
    "        c_loss = has_obj_c_loss + binary_weight*no_obj_c_loss\n",
    "\n",
    "        p_true = y_true[..., -class_num:] # N*S*S*C\n",
    "        p_pred = y_pred[..., -class_num:] # N*S*S*C\n",
    "        p_pred = tf.clip_by_value(p_pred, epsilon, 1 - epsilon)\n",
    "        p_loss = -tf.reduce_sum(\n",
    "            tf.reduce_mean(\n",
    "                has_obj_mask # N*S*S*1\n",
    "                *p_true*tf.math.log(p_pred), # N*S*S*C\n",
    "                axis=0))\n",
    "\n",
    "        loss = (loss_weight[0]*xy_loss\n",
    "                + loss_weight[1]*wh_loss\n",
    "                + loss_weight[2]*c_loss\n",
    "                + loss_weight[3]*p_loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return yolo_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import binary_accuracy\n",
    "\n",
    "#  Object Accuracy\n",
    "def wrap_obj_acc(grid_shape, bbox_num, class_num):\n",
    "    def obj_acc(y_true, y_pred):\n",
    "        y_true = tf.reshape(\n",
    "            y_true[..., :-class_num],\n",
    "            (-1, *grid_shape, 1, 5)) # N*S*S*1*5\n",
    "        y_pred = tf.reshape(\n",
    "            y_pred[..., :-class_num],\n",
    "            (-1, *grid_shape, bbox_num, 5)) # N*S*S*B*5\n",
    "        \n",
    "        c_true = y_true[..., 4] # N*S*S*1\n",
    "        c_pred = tf.reduce_max(y_pred[..., 4], # N*S*S*B\n",
    "                               axis=-1,\n",
    "                               keepdims=True) # N*S*S*1\n",
    "\n",
    "        bi_acc = binary_accuracy(c_true, c_pred)\n",
    "\n",
    "        return bi_acc\n",
    "    return obj_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IOU\n",
    "def wrap_mean_iou(grid_shape, bbox_num, class_num):\n",
    "    def mean_iou(y_true, y_pred):\n",
    "        y_true = tf.reshape(\n",
    "            y_true[..., :-class_num],\n",
    "            (-1, *grid_shape, 1, 5)) # N*S*S*1*5\n",
    "        y_pred = tf.reshape(\n",
    "            y_pred[..., :-class_num],\n",
    "            (-1, *grid_shape, bbox_num, 5)) # N*S*S*B*5\n",
    "\n",
    "        has_obj_mask = y_true[..., 4] # N*S*S*1\n",
    "        \n",
    "        iou_scores = cal_iou(y_true, y_pred, grid_shape) # N*S*S*B\n",
    "        iou_scores = tf.reduce_max(iou_scores, axis=-1, keepdims=True) # N*S*S*1\n",
    "        iou_scores = iou_scores*has_obj_mask # N*S*S*1\n",
    "\n",
    "        num_p = tf.reduce_sum(has_obj_mask)\n",
    "\n",
    "        return tf.reduce_sum(iou_scores)/(num_p + epsilon)\n",
    "    return mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Accuracy\n",
    "def wrap_class_acc(grid_shape, bbox_num, class_num):\n",
    "    def class_acc(y_true, y_pred):\n",
    "        y_true = tf.reshape(\n",
    "            y_true[..., :-class_num],\n",
    "            (-1, *grid_shape, 5)) # N*S*S*5\n",
    "\n",
    "        has_obj_mask = y_true[..., 4] # N*S*S\n",
    "\n",
    "        pi_true = tf.argmax(y_true[..., -class_num:], # N*S*S*C\n",
    "                            axis=-1) # N*S*S\n",
    "        pi_pred = tf.argmax(y_pred[..., -class_num:], # N*S*S*C\n",
    "                            axis=-1) # N*S*S\n",
    "\n",
    "        equal_mask = tf.cast(pi_true == pi_pred,\n",
    "                             dtype=y_true.dtype) # N*S*S\n",
    "        equal_mask = equal_mask*has_obj_mask # N*S*S\n",
    "\n",
    "        num_p = tf.reduce_sum(has_obj_mask)\n",
    "\n",
    "        return tf.reduce_sum(equal_mask)/(num_p + epsilon)\n",
    "    return class_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Class for Model, Loss, Metrics\n",
    "class Yolo(object):\n",
    "    def __init__(self,\n",
    "                 input_shape=(448, 448, 3),\n",
    "                 class_names=[]):\n",
    "        self.input_shape = input_shape\n",
    "        self.grid_shape = input_shape[0]//64, input_shape[1]//64\n",
    "        self.bbox_num = 2\n",
    "        self.class_names = class_names\n",
    "        self.class_num = len(class_names)\n",
    "        self.model = None\n",
    "        self.file_names = None\n",
    "\n",
    "    ## Model Create\n",
    "    def create_model(self,\n",
    "                     bbox_num=2,\n",
    "                     pretrained_weights=None,\n",
    "                     pretrained_darknet=None):\n",
    "        \n",
    "        model_body = yolo_neck(self.input_shape,\n",
    "                               pretrained_darknet)\n",
    "\n",
    "        self.model = yolo_head(model_body,\n",
    "                               bbox_num,\n",
    "                               self.class_num)\n",
    "         \n",
    "        if pretrained_weights is not None:\n",
    "            self.model.load_weights(pretrained_weights)\n",
    "        self.grid_shape = self.model.output.shape[1:3]\n",
    "        self.bbox_num = bbox_num\n",
    "\n",
    "    ## Load Create\n",
    "    def loss(self,\n",
    "             binary_weight,\n",
    "             loss_weight=[5, 5, 1, 1]):\n",
    "        \n",
    "        if isinstance(loss_weight, dict):\n",
    "            loss_weight_list = []\n",
    "            loss_weight_list.append(loss_weight[\"xy\"])\n",
    "            loss_weight_list.append(loss_weight[\"wh\"])\n",
    "            loss_weight_list.append(loss_weight[\"conf\"])\n",
    "            loss_weight_list.append(loss_weight[\"prob\"])\n",
    "            loss_weight = loss_weight_list\n",
    "        \n",
    "        return wrap_yolo_loss(\n",
    "            grid_shape=self.grid_shape,\n",
    "            bbox_num=self.bbox_num, \n",
    "            class_num=self.class_num,\n",
    "            binary_weight=binary_weight,\n",
    "            loss_weight=loss_weight,\n",
    "            )\n",
    "    \n",
    "    ## Metrics Create\n",
    "    def metrics(self, type=\"obj_acc\"):\n",
    "        \n",
    "        metrics_list = []     \n",
    "        if \"obj\" in type:\n",
    "            metrics_list.append(\n",
    "                wrap_obj_acc(\n",
    "                    self.grid_shape, \n",
    "                    self.bbox_num, \n",
    "                    self.class_num))\n",
    "        if \"iou\" in type:\n",
    "            metrics_list.append(\n",
    "                wrap_mean_iou(\n",
    "                    self.grid_shape, \n",
    "                    self.bbox_num, \n",
    "                    self.class_num))\n",
    "        if \"class\" in type:\n",
    "            metrics_list.append(\n",
    "                wrap_class_acc(\n",
    "                    self.grid_shape, \n",
    "                    self.bbox_num, \n",
    "                    self.class_num))\n",
    "        \n",
    "        return metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Number Plate Region\\env\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Number Plate Region\\env\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 448, 448, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)         9472      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 224, 224, 64)         256       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)     (None, 224, 224, 64)         0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 64)         0         ['leaky_re_lu[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 192)        110784    ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 112, 112, 192)        768       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 112, 112, 192)        0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 192)          0         ['leaky_re_lu_1[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 128)          24704     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 56, 56, 128)          512       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 56, 56, 128)          0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 256)          295168    ['leaky_re_lu_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 56, 56, 256)          1024      ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 56, 56, 256)          0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)          65792     ['leaky_re_lu_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 56, 56, 256)          1024      ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 56, 56, 256)          0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 512)          1180160   ['leaky_re_lu_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 56, 56, 512)          2048      ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 56, 56, 512)          0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 512)          0         ['leaky_re_lu_5[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 256)          131328    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 28, 28, 256)          1024      ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 28, 28, 256)          0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)          1180160   ['leaky_re_lu_6[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 28, 28, 512)          2048      ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 28, 28, 512)          0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 256)          131328    ['leaky_re_lu_7[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 28, 28, 256)          1024      ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 28, 28, 256)          0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)          1180160   ['leaky_re_lu_8[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 28, 28, 512)          2048      ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 28, 28, 512)          0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 28, 28, 256)          131328    ['leaky_re_lu_9[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 28, 28, 256)          1024      ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 28, 28, 256)          0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 512)          1180160   ['leaky_re_lu_10[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 28, 28, 512)          2048      ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 28, 28, 512)          0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 256)          131328    ['leaky_re_lu_11[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 28, 28, 256)          1024      ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 28, 28, 256)          0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 28, 28, 512)          1180160   ['leaky_re_lu_12[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 28, 28, 512)          2048      ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 28, 28, 512)          0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 28, 28, 1024)         4719616   ['leaky_re_lu_13[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 28, 28, 1024)         4096      ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 28, 28, 1024)         0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 1024)         0         ['leaky_re_lu_14[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 14, 14, 512)          524800    ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 14, 14, 512)          2048      ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 14, 14, 512)          0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 1024)         4719616   ['leaky_re_lu_15[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 14, 14, 1024)         4096      ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 14, 14, 1024)         0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 14, 14, 512)          524800    ['leaky_re_lu_16[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 14, 14, 512)          2048      ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 14, 14, 512)          0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 14, 14, 1024)         4719616   ['leaky_re_lu_17[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 14, 14, 1024)         4096      ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 14, 14, 1024)         0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 14, 14, 1024)         9438208   ['leaky_re_lu_18[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 14, 14, 1024)         4096      ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 14, 14, 1024)         0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 7, 7, 1024)           9438208   ['leaky_re_lu_19[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 7, 7, 1024)           4096      ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 7, 7, 1024)           0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 7, 7, 1024)           9438208   ['leaky_re_lu_20[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 7, 7, 1024)           4096      ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 7, 7, 1024)           0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 7, 7, 1024)           9438208   ['leaky_re_lu_21[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 7, 7, 1024)           4096      ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 7, 7, 1024)           0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 7, 7, 10)             10250     ['leaky_re_lu_22[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 7, 7, 10)             10250     ['leaky_re_lu_22[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 7, 7, 20)             0         ['conv2d_23[0][0]',           \n",
      "                                                                     'conv2d_24[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 59964500 (228.75 MB)\n",
      "Trainable params: 59939156 (228.65 MB)\n",
      "Non-trainable params: 25344 (99.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Buld NN model from class\n",
    "yolo = Yolo(class_names=class_names)\n",
    "yolo.create_model()\n",
    "yolo.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizer\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch <= 20:\n",
    "        return lr\n",
    "    elif epoch <= 70:\n",
    "        return 3e-5\n",
    "    else:\n",
    "        return 1e-5\n",
    "    \n",
    "callback = LearningRateScheduler(schedule=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00192398]\n"
     ]
    }
   ],
   "source": [
    "## Loss Funtion from YOLO class\n",
    "from utils.tools import get_class_weight\n",
    "\n",
    "binary_weight = get_class_weight(\n",
    "    train_label[..., 4:5],\n",
    "    method='binary'\n",
    "    )\n",
    "print(binary_weight)\n",
    "\n",
    "loss_weight = {\n",
    "    \"xy\":5,\n",
    "    \"wh\":5,\n",
    "    \"conf\":1,\n",
    "    \"prob\":1\n",
    "    }\n",
    "\n",
    "loss_fn = yolo.loss(\n",
    "    binary_weight=binary_weight,\n",
    "    loss_weight=loss_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Metrics from Yolo Class\n",
    "\n",
    "metrics = yolo.metrics('obj+iou+class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model compilation\n",
    "\n",
    "yolo.model.compile(optimizer=optimizer,\n",
    "                   loss=loss_fn,\n",
    "                   metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img_tmp = train_img[None, ...]\n",
    "# train_label_tmp = train_label[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\Number Plate Region\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\20133\\AppData\\Local\\Temp\\ipykernel_7468\\4032179137.py\", line 9, in yolo_loss  *\n        xywhc_true = tf.reshape(\n\n    ValueError: Cannot reshape a tensor with 78400 elements to shape [5,7,7,1,5] (1225 elements) for '{{node yolo_loss/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](yolo_loss/strided_slice, yolo_loss/Reshape/shape)' with input shapes: [5,7,448,5], [5] and with input tensors computed as partial shapes: input[1] = [5,7,7,1,5].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m valid_img  \u001b[38;5;241m=\u001b[39m test_img\n\u001b[0;32m      5\u001b[0m valid_label \u001b[38;5;241m=\u001b[39m test_label\n\u001b[1;32m----> 7\u001b[0m train_history \u001b[38;5;241m=\u001b[39m \u001b[43myolo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Number Plate Region\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewshixwnt.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filely2_btz1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__yolo_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     13\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     14\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 15\u001b[0m xywhc_true \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_num\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m xywhc_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreshape, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(class_num)], (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(grid_shape), ag__\u001b[38;5;241m.\u001b[39mld(bbox_num), \u001b[38;5;241m5\u001b[39m)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     17\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(ag__\u001b[38;5;241m.\u001b[39mld(y_true)\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\Number Plate Region\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\20133\\AppData\\Local\\Temp\\ipykernel_7468\\4032179137.py\", line 9, in yolo_loss  *\n        xywhc_true = tf.reshape(\n\n    ValueError: Cannot reshape a tensor with 78400 elements to shape [5,7,7,1,5] (1225 elements) for '{{node yolo_loss/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](yolo_loss/strided_slice, yolo_loss/Reshape/shape)' with input shapes: [5,7,448,5], [5] and with input tensors computed as partial shapes: input[1] = [5,7,7,1,5].\n"
     ]
    }
   ],
   "source": [
    "## Model Training and Validation\n",
    "import time\n",
    "start_time = time.time()\n",
    "valid_img  = test_img\n",
    "valid_label = test_label\n",
    "\n",
    "train_history = yolo.model.fit(\n",
    "    train_img,\n",
    "    train_label,\n",
    "    epochs = n_epoch,\n",
    "    batch_size=5,\n",
    "    verbose=1,\n",
    "    validation_data=(valid_img, valid_label),\n",
    "    callbacks=[callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 448, 448, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_img.shape)\n",
    "print(train_img.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
